{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from qadence import *\n",
    "import torch\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8945],\n",
      "        [0.8510],\n",
      "        [0.7682],\n",
      "        [0.6543],\n",
      "        [0.5204],\n",
      "        [0.3796],\n",
      "        [0.2457],\n",
      "        [0.1318],\n",
      "        [0.0490],\n",
      "        [0.0055]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def generate_chebyshev_grid(n, a=0, b=0.9, requires_grad=True):\n",
    "    k = torch.arange(n)\n",
    "    chebyshev_nodes = torch.cos(torch.pi * (2*k + 1) / (2*n))  #standard Chebyshev nodes in [-1,1]\n",
    "    scaled_nodes = ((chebyshev_nodes + 1) / 2) * (b - a) + a  #rescale to [a, b]\n",
    "    \n",
    "    return scaled_nodes.requires_grad_(requires_grad=requires_grad)\n",
    "\n",
    "N_POINTS = 10\n",
    "x = generate_chebyshev_grid(N_POINTS)\n",
    "cp = torch.reshape(x, (N_POINTS,1))\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_POINTS = 10\n",
    "#cp = torch.linspace(0.0, 0.9, N_POINTS, requires_grad=True)\n",
    "#cp = torch.reshape(cp, (N_POINTS,1))\n",
    "#print(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Pennylane:  [0.05815449 0.9552357  0.84251973 0.62340308 0.03134017 0.25185522\n",
      " 0.06291017 0.92875258 0.87050104 0.437279   0.04036647 0.23340819\n",
      " 0.12358607 0.08354337 0.37753296 0.07473488 0.93190879 0.2256651\n",
      " 0.05258016 0.13264067 0.61243659 0.68343022 0.15212583 0.3175678\n",
      " 0.5261719  0.1570535  0.08810978 0.31223868 0.26504491 0.61440828\n",
      " 0.47678475 0.37536703 0.70118189 0.30905878 0.13043349 0.59777135]\n",
      "tensor([[0.8945],\n",
      "        [0.8510],\n",
      "        [0.7682],\n",
      "        [0.6543],\n",
      "        [0.5204],\n",
      "        [0.3796],\n",
      "        [0.2457],\n",
      "        [0.1318],\n",
      "        [0.0490],\n",
      "        [0.0055]], requires_grad=True)\n",
      "f(x):  tensor([[ 1.1674],\n",
      "        [ 0.8659],\n",
      "        [ 0.2610],\n",
      "        [ 0.3621],\n",
      "        [ 0.4366],\n",
      "        [-0.2086],\n",
      "        [-0.4951],\n",
      "        [-0.4556],\n",
      "        [-0.5015],\n",
      "        [-0.5827]], grad_fn=<CatBackward0>)\n",
      "f(0):  tensor([[-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952],\n",
      "        [-0.5952]], grad_fn=<CatBackward0>)\n",
      "tensor([[2.7626],\n",
      "        [2.4611],\n",
      "        [1.8562],\n",
      "        [1.9574],\n",
      "        [2.0318],\n",
      "        [1.3866],\n",
      "        [1.1001],\n",
      "        [1.1396],\n",
      "        [1.0937],\n",
      "        [1.0125]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 5.6634],\n",
      "        [ 8.1735],\n",
      "        [ 4.2275],\n",
      "        [-3.4975],\n",
      "        [ 3.1948],\n",
      "        [ 4.1760],\n",
      "        [ 0.2160],\n",
      "        [-0.2200],\n",
      "        [ 1.4418],\n",
      "        [ 2.2281]], grad_fn=<SliceBackwardBackward0>)\n",
      "0 422.6766149546991\n"
     ]
    }
   ],
   "source": [
    "N_QUBITS = 6\n",
    "DEPTH = 2\n",
    "LEARNING_RATE = 0.1\n",
    "lamb = 8\n",
    "\n",
    "torch.manual_seed(42)\n",
    "ansatz = hea(n_qubits=N_QUBITS, depth=DEPTH, operations=[RZ, RX, RZ])\n",
    "\n",
    "chebT = feature_map(n_qubits=N_QUBITS, param=\"x\", op=RY, fm_type = BasisSet.CHEBYSHEV, reupload_scaling = ReuploadScaling.TOWER)\n",
    "fm = chebT\n",
    "\n",
    "obs = total_magnetization(N_QUBITS)\n",
    "circuit = QuantumCircuit(N_QUBITS, chain(fm, ansatz))\n",
    "model = QNN(circuit=circuit, observable=obs, inputs=[\"x\"])\n",
    "\n",
    "inital_vparams = model.vparams\n",
    "#print(\"Inital: \",inital_vparams)\n",
    "sorted_keys = sorted(inital_vparams.keys(), key=lambda k: int(k.split('_')[1]))\n",
    "inital_thetas = np.array([inital_vparams[k].item() for k in sorted_keys])\n",
    "inital_thetas = np.reshape(inital_thetas, (DEPTH, 3, N_QUBITS))\n",
    "Theta_init = np.transpose(inital_thetas, (2, 0, 1))\n",
    "theta_init = Theta_init.reshape(-1)\n",
    "print(\"For Pennylane: \",theta_init)\n",
    "#check\n",
    "#Theta_init = np.reshape(theta_init, (N_QUBITS,DEPTH,3))\n",
    "#print(\"Theta: \",Theta_init)\n",
    "\n",
    "def loss_fn(inputs: torch.tensor, outputs: torch.tensor) -> torch.tensor:\n",
    "    print(\"f(x): \",outputs)\n",
    "    print(\"f(0): \",model(torch.zeros_like(inputs)))\n",
    "    boundary_loss = 1*torch.ones_like(inputs) - model(torch.zeros_like(inputs))\n",
    "    outputs = outputs + boundary_loss\n",
    "    print(outputs)\n",
    "    df = grad(outputs=outputs.sum(), inputs=inputs, create_graph=True)[0] \n",
    "    print(df)\n",
    "    f = lamb*outputs*(0.1+torch.tan(lamb*inputs))\n",
    "    ode_loss = (df+f).pow(2)\n",
    "\n",
    "    return ode_loss.mean()  \n",
    "\n",
    "\n",
    "## TRAINING ##\n",
    "epochs = 1\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    #cp = torch.linspace(0.0, 0.9, N_POINTS, requires_grad=True) \n",
    "    #cp = torch.reshape(cp, (N_POINTS,1)) \n",
    "    cp = cp.clone().detach().requires_grad_(True)\n",
    "    print(cp)\n",
    "    \n",
    "    loss = loss_fn(inputs=cp, outputs=model(cp))\n",
    "    losses.append(loss.item())\n",
    "    if (epoch % 50 == 0):\n",
    "        print(epoch, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
